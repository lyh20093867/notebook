### uptime与平均负载
```
[hadoop@m-19-79 ~]$ uptime
 16:17:27 up 93 days,  6:08,  3 users,  load average: 3.73, 2.49, 1.69
 当前时间   系统运行时间        正在登录用户数   过去1、5、15分钟的平均负载
```
通过man uptime查看对uptime的介绍可知，系统平均负载是在过去一段时间内处于runnable(可运行状态)和uninterruptale(不可中断状态)状态的平均进程数,也就是平均活跃进程数；   
可运行状态的进程，一般指正在使用cpu或者正在**等待cpu的进程**，ps命令中处于R状态的进程;  
不可终端状态的进程指正处于内核态关键流程中的进程，并且这些流程是不可以被打断的，比如等**待硬件设备的io响应**，对应ps命令中的D状态的进程;
```
System load averages is the average number of processes that are either in a runnable or uninterruptable state.  A process in a runnable state is either using the CPU or waiting  to  use  the
       CPU.   A process in uninterruptable state is waiting for some I/O access, eg waiting for disk.  The averages are taken over the three time intervals.  Load averages are not normalized for the
       number of CPUs in a system, so a load average of 1 means a single CPU system is loaded all the time while on a 4 CPU system it means it was idle 75% of the time.
```
#### 查看cpu情况
可以通过lscpu查看服务器cpu的情况
```
[hadoop@m-19-79 ~]$ lscpu
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                40
On-line CPU(s) list:   0-39
Thread(s) per core:    2
Core(s) per socket:    10
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz
Stepping:              1
CPU MHz:               1200.305
CPU max MHz:           3100.0000
CPU min MHz:           1200.0000
BogoMIPS:              4399.71
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              25600K
NUMA node0 CPU(s):     0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38
NUMA node1 CPU(s):     1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts
```
通过查看/proc/cpuinfo查看cpu的情况
```
grep 'model name' /proc/cpuinfo | wc -l
```
建议当平均负载**高于cpu数量的70%的时候**，可以认为，过载了，需要查询负载过高的原因了；

#### cpu使用率
cpu是单位时间内cpu繁忙情况的统计，而平均负载是单位时间处于可运行状态和不可中断状态的进程数，包括了正在使用cpu的进程和等待cpu和等待IO的进程，cpu使用率只反应了正在使用cpu的情况，不包括等待IO的情况；   
计算(cpu)密集型任务，使用大量cpu会导致平均负载升高，cpu使用率跟平均负载一一对应；   
io密集型任务，等待io任务也会导致平均负载升高，但是cpu可能处于空闲状态而cpu使用率不高，此时不一一对应;   
大量等待cpu的进程会导致平均负载升高，此时cpu使用率也会升高，此时一一对应；    
```
sudo yum install -y epel-release
sudo yum install -y stress
sudo yum install -y sysstat
```
### 平均负载案例分析
使用iostat、mapstat、pidstat等工具找出平均负载升高的原因，系统预先装上stress和sysstat包，其中stress包是在linux中做系统压力测试的工具，sysstat包含了常用的linux性能工具，用来监控和分析系统的性能；   
mapstat是常用的多核cpu性能分析工具，用于实时查看每个cpu的性能指标，所有cpu的平均指标；  
pidstat是常用的进程性能分析工具，用于实时查看进程的cpu、内存、IO以及上下文切换   

#### 启动虚拟机(vm或者vbox)
启动三台虚拟机，需要以root用户运行；   
安装stress包和sysstat包；  
#### 执行案例
##### cpu密集型
在第一台终端上运行命令：   
```
stress -c 10 --timeout 600
stress --cpu 1 --timeout 600
```
在第二台终端上运行命令：   
-d 参数表示高亮显示变化的区域
```
watch -d uptime
```
在第三台终端上运行命令：   
 -P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据
```
mpstat -P ALL 5
[hadoop@m-19-79 logs]$ mpstat -P ALL 5
Linux 3.10.0-957.1.3.el7.x86_64 (m-19-79) 	01/20/2020 	_x86_64_	(40 CPU)

05:51:56 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:52:01 PM  all    0.38    0.00    0.10    0.09    0.00    0.01    0.00    0.00    0.00   99.42
05:52:01 PM    0    0.20    0.00    0.20    0.60    0.00    0.20    0.00    0.00    0.00   98.80
05:52:01 PM    1    0.20    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.80
05:52:01 PM    2    0.00    0.00    0.20    0.00    0.00    0.00    0.00    0.00    0.00   99.80
05:52:01 PM    3    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM    4    0.40    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.60
05:52:01 PM    5    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM    6    0.40    0.00    0.60    0.00    0.00    0.00    0.00    0.00    0.00   99.00
05:52:01 PM    7    0.60    0.00    0.40    0.00    0.00    0.00    0.00    0.00    0.00   99.00
05:52:01 PM    8    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM    9    0.20    0.00    0.20    0.00    0.00    0.00    0.00    0.00    0.00   99.60
05:52:01 PM   10    0.20    0.00    0.20    0.00    0.00    0.20    0.00    0.00    0.00   99.40
05:52:01 PM   11    0.60    0.00    0.20    0.40    0.00    0.00    0.00    0.00    0.00   98.80
05:52:01 PM   12    0.20    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.80
05:52:01 PM   13    0.80    0.00    0.20    0.40    0.00    0.00    0.00    0.00    0.00   98.60
05:52:01 PM   14    0.60    0.00    0.20    0.80    0.00    0.20    0.00    0.00    0.00   98.20
05:52:01 PM   15    0.20    0.00    0.40    0.00    0.00    0.00    0.00    0.00    0.00   99.40
05:52:01 PM   16    0.00    0.00    0.00    1.81    0.00    0.00    0.00    0.00    0.00   98.19
05:52:01 PM   17    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   18    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   19    3.60    0.00    0.20    0.00    0.00    0.00    0.00    0.00    0.00   96.20
05:52:01 PM   20    0.00    0.00    0.20    0.00    0.00    0.20    0.00    0.00    0.00   99.60
05:52:01 PM   21    5.99    0.00    0.20    0.00    0.00    0.00    0.00    0.00    0.00   93.81
05:52:01 PM   22    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   23    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   24    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   25    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   26    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   27    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   28    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   29    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   30    0.20    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.80
05:52:01 PM   31    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   32    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   33    0.20    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.80
05:52:01 PM   34    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   35    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   36    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   37    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:52:01 PM   38    0.20    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.80
05:52:01 PM   39    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
```

##### io密集型

在第一台终端上运行命令：   
```
stress -i 1 --timeout 600
```
在第二台终端上运行命令：   
-d 参数表示高亮显示变化的区域
```
watch -d uptime
```
在第三台终端上运行命令：   
 -P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据
```
mpstat -P ALL 5

pidstat -d 5
```

##### 大量进程型

在第一台终端上运行命令：   
```
stress -c 8 --timeout 600
```
在第二台终端上运行命令：   
-d 参数表示高亮显示变化的区域
```
watch -d uptime
```
在第三台终端上运行命令：   
 -P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据
```
watch -d uptime
```
### htop和atop的安装与使用
#### htop和atop的安装
```
sudo yum install -y ncurses-devel
sudo yum install -y htop
sudo yum install -y atop
```

### cpu上下文切换
#### cpu上下文
cpu执行任务需要知道从哪里加载，从哪里开始运行，获取这些信息需要从程序计数器(pc)和cpu的各种寄存器中读取信息，这些信息就是cpu上下文;   
#### cpu上下文切换
先把上一个任务的cpu上下文保存起来，然后加载新任务的上下文到寄存器和程序计数器中，再跳转到程序计数器所指定的新位置运行新的任务；

存储起来的cpu上下文保存在系统内核(的内存)中，并在任务重新调度执行的时候再次加载进来，这样就能保证任务原来的状态不受影响，让任务看起来是连续运行的。   

linux中的任务上下文切换主要包括进程上下文切换、线程上下文切换和中断上下文切换；   
cpu上下文的切换过程中可能涉及到从用户态切换到内核态，这个过程需要**系统调用**来完成，会有资源消耗；   
系统调用的过程会发生两次cpu上下文切换，从用户态切到内核态一次，从内核态切换到用户态又是一次，是特权模式切换； 
##### 进程上下文切换  
进程上下文切换是一个进程切换到了另外一个进程，进程是由内核管理和调度的，进程切换只会发生在内核态中；   
系统调用过程中一直是同一个进程在运行；  
linux通过tlb来管理虚拟内存到物理内存的映射关系，linux为每个cpu维护了一个就绪队列；   
一个进程执行终止，cpu被释放出来再从就绪队列中拿新的进程运行时会存在进程切换；  
进程的时间片使用完后，系统会先挂起当前的进程，然后从就绪队列中取出新的进程运行，就会存在进程调度；   
当系统资源不足的时候，系统会挂起当前的进程，调度其他新的进程执行；   
当进程通过sleep睡眠函数主动将自己挂起的时候，系统会调度其他新的进程执行；   
当有优先级更高的进程运行时，当前进程会被挂起，转而运行更高优先级的进程；   
当发生硬件中断时，cpu上的进程会被挂起，转而执行内核中的中断服务程序；   
##### 线程上下文切换
线程是调度的基本单位，进程是资源拥有的基本单位；   
当进程只有一个线程时，线程跟进程没有什么区别；  
当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在线程上下文切换的时候是不需要修改的，但是线程私有的线程栈和寄存器是需要保存下来的；     

第一种，前后两个线程属于不同的进程，因为资源不共享，切换过程跟进程上下文切换是一样的；    
第二种，前后两个线程属于同一个进程，进程资源共享的部分不动，只需要切换线程私有部分的东西；   

##### 中断上下文切换
为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序响应设备事件。中断上下文切换不会涉及到进程的用户态，只包括内核态中断服务程序执行所必须的状态，包括cpu寄存器、内核堆栈、硬件中断参数等，所以即便中断过程打断的是一个正处于用户态的进程，不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。     
对同一个cpu来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。


##### 如何查看系统的上下文切换
vmstat是一个常用的系统性能分析工具，用于分析系统的内存使用情况和cpu上下文切换和中断的次数。     

```
[hadoop@m-19-90 ~]$ vmstat 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff     cache      si   so   bi    bo   in   cs    us  sy  id wa st
 2  1   7680 123057048  0     13246080    0    0   185   484    0    0    7   1   91  0  0
 2  0   7680 123213008  0     12975416    0    0 13942 49704 83233 17741  23  1   75  1  0
 2  0   7680 123211024  0     12879548    0    0  8690 19842 48518 21713  7   1   91  0  0
29  0   7680 122958936  0     12890900    0    0 10776  2540 53505 14882  3   1   96  0  0

cs(context switch) 每秒**上下文切换的次数**；
in(interrupt)  每秒中断的次数，包括了时钟中断；
r(running or runnable)  就绪队列的长度，也就是正在运行和等待cpu的进程数；
b(blocked) 处于不可中断睡眠状态的进程数；
其他的详细信息可以通过man vmstat进行查看
```
vmstat给出系统总体的上下文切换情况，pidstat可以查看每一个进程的上下文切换
```每隔5秒输出1组数据
[hadoop@m-19-79 ~]$ pidstat -w 5
Linux 3.10.0-957.1.3.el7.x86_64 (m-19-79) 	01/22/2020 	_x86_64_	(40 CPU)

01:56:35 PM   UID       PID   cswch/s nvcswch/s  Command
01:56:40 PM     0         3      0.60      0.00  ksoftirqd/0
01:56:40 PM     0        10    331.35      0.00  rcu_sched
01:56:40 PM     0        12      0.20      0.00  watchdog/0
01:56:40 PM     0        13      0.20      0.00  watchdog/1
01:56:40 PM     0        15      0.20      0.00  ksoftirqd/1
01:56:40 PM     0        19      0.20      0.00  watchdog/2
01:56:40 PM     0        21      0.40      0.00  ksoftirqd/2
01:56:40 PM     0        24      0.20      0.00  watchdog/3
01:56:40 PM     0        29      0.20      0.00  watchdog/4
01:56:40 PM     0        31      0.79      0.00  ksoftirqd/4
01:56:40 PM     0        34      0.20      0.00  watchdog/5


```
cswch(voluntary context switches) 表示每秒自愿上下文切换的次数；    
nvcswch(non voluntary context switches) 表示每秒非自愿上下文切换的次数；    

自愿上下文切换是指进程无法获取所需资源，导致的上下文切换。非自愿上下文切换，指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。  
自愿上下文切换变多了，说明进程都在等待资源，有可能发生了IO等其他的问题；非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢CPU，说明CPU可能成为了瓶颈；   
不过中断次数变多了，还需要通过查看/proc/interrupts文件来分析具体的中断类型。

pidstat可以通过-p 指定进程号监控指定的进程状态信息；也可以通过-T 指定线程号监控指定的线程状态信息；通过-w 查看系统上下文切换情况；-u 指定输出cpu的使用指标；

```监控进程号为56060的进程，每4秒钟输出一次统计信息
[hadoop@m-19-90 ~]$ pidstat -p 56060 4
Linux 3.10.0-957.12.1.el7.x86_64 (m-19-90) 	01/22/2020 	_x86_64_	(40 CPU)

11:59:20 AM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
11:59:24 AM  1500     56060    0.00   10.00    0.00   10.00    22  java
11:59:28 AM  1500     56060    0.00    7.75    0.00    7.75    22  java
11:59:32 AM  1500     56060    0.00   12.25    0.00   12.25    22  java


时间   上午   用户id   进程id  
%usr 进程在用户态下cpu的使用百分比
%system  进程在内核态下cpu使用的百分比
```

### 模拟上下文切换过多
#### 安装sysbench 
sysbench 是一个多线程的基准测试工具，用来评估不同系统参数下的数据负载情况；  
```
sudo yum install -y sysbench
```
#### 第一个终端运行sysbench模拟系统多线程调度的瓶颈 
```$xslt
[hadoop@mj-9-85 ~]$ lscpu
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    1
Core(s) per socket:    1
座：                 8
NUMA 节点：         1
厂商 ID：           GenuineIntel
CPU 系列：          6
型号：              13
型号名称：        QEMU Virtual CPU version (cpu64-rhel6)
步进：              3
CPU MHz：             2297.338
BogoMIPS：            4594.67
超管理器厂商：  KVM
虚拟化类型：     完全
L1d 缓存：          32K
L1i 缓存：          32K
L2 缓存：           4096K
NUMA 节点0 CPU：    0-7

```
本次测试服务器为8核服务器   
运行sysbench
```
[hadoop@mj-9-85 ~]$ sysbench --threads=100 --max-time=300 threads run
WARNING: --max-time is deprecated, use --time instead
sysbench 1.0.17 (using system LuaJIT 2.0.4)

Running the test with following options:
Number of threads: 100
Initializing random number generator from current time


Initializing worker threads...

Threads started!


General statistics:
    total time:                          300.0301s
    total number of events:              946630

Latency (ms):
         min:                                    0.31
         avg:                                   31.69
         max:                                 1316.09
         95th percentile:                       81.48
         sum:                             29999178.90

Threads fairness:
    events (avg/stddev):           9466.3000/103.97
    execution time (avg/stddev):   299.9918/0.01
```
##### 在第二个终端运行vmstat 
```
lan_dev@mj-9-33:~$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 662896 142448 2969116    0    0     0     0   17   18  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   17   20  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   33   45  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   22   34  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   11   12  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   24   37  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   29   34  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   19   29  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   24   30  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   17   20  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   10   12  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   23   35  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   22   29  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   21   34  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   26   29  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   16   20  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0    8   13  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   33   50  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   15   12  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   11   18  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   21   27  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   19   26  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   21   26  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   32   47  0  1 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   11   14  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   16   22  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   27   34  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   24   36  0  0 100  0  0
 1  0      0 662896 142448 2969116    0    0     0     0   10   10  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   27   39  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   11   14  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   16   18  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   27   45  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   26   41  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   21   24  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   28   33  0  0 100  0  0
 0  0      0 662896 142448 2969116    0    0     0     0   19   30  0  0 100  0  0
```
从上图可以看出，系统完全能够承受100的线程，cs上下文切换在20左右，同时us核sy的使用都为0，而id为100，说明cpu基本上是空闲的，前面的r多数为0，说明就绪队列的进程数为0


##### 在第三个终端运行pidstat
```$xslt
[hadoop@mj-9-85 ~]$ pidstat -wt 5
Linux 3.10.0-229.el7.x86_64 (mj-9-85) 	2020年01月22日 	_x86_64_	(8 CPU)

14时39分54秒   UID      TGID       TID   cswch/s nvcswch/s  Command
14时39分59秒     0         3         -      0.20      0.00  ksoftirqd/0
14时39分59秒     0         -         3      0.20      0.00  |__ksoftirqd/0
14时39分59秒     0         7         -      0.60      0.00  migration/0
14时39分59秒     0         -         7      0.60      0.00  |__migration/0
14时39分59秒     0        17         -     32.27      0.00  rcu_sched
14时39分59秒     0         -        17     32.27      0.00  |__rcu_sched
14时39分59秒     0        18         -      1.59      0.00  rcuos/0
14时39分59秒     0         -        18      1.59      0.00  |__rcuos/0
14时39分59秒     0        19         -      4.58      0.00  rcuos/1
14时39分59秒     0         -        19      4.58      0.00  |__rcuos/1
14时39分59秒     0        20         -      6.77      0.00  rcuos/2
14时39分59秒     0         -        20      6.77      0.00  |__rcuos/2
14时39分59秒     0        22         -      0.20      0.00  rcuos/4
14时39分59秒     0         -        22      0.20      0.00  |__rcuos/4
```
```$xslt
[hadoop@mj-9-85 ~]$ pidstat -u 1
Linux 3.10.0-229.el7.x86_64 (mj-9-85) 	2020年01月22日 	_x86_64_	(8 CPU)

14时41分13秒   UID       PID    %usr %system  %guest    %CPU   CPU  Command
14时41分14秒  1004     29937    0.99    0.00    0.00    0.99     2  htop

14时41分14秒   UID       PID    %usr %system  %guest    %CPU   CPU  Command
14时41分15秒     0        25    0.00    1.00    0.00    1.00     0  rcuos/7
14时41分15秒     0     10003    1.00    0.00    0.00    1.00     5  python
14时41分15秒  1004     29937    0.00    1.00    0.00    1.00     2  htop
14时41分15秒  1004     32512    0.00    1.00    0.00    1.00     6  pidstat
```
```$xslt
[hadoop@mj-9-85 ~]$ pidstat -w 1
Linux 3.10.0-229.el7.x86_64 (mj-9-85) 	2020年01月22日 	_x86_64_	(8 CPU)

14时41分45秒   UID       PID   cswch/s nvcswch/s  Command
14时41分46秒     0        17     35.00      0.00  rcu_sched
14时41分46秒     0        18      6.00      0.00  rcuos/0
14时41分46秒     0        20      6.00      0.00  rcuos/2
14时41分46秒     0        23     10.00      0.00  rcuos/5
14时41分46秒     0        25      7.00      0.00  rcuos/7
14时41分46秒     0        53      1.00      0.00  migration/6
14时41分46秒     0       549      1.00      0.00  gssproxy
14时41分46秒     0       767      1.00      1.00  snmpd
14时41分46秒   997      1821      1.00      0.00  zabbix_agentd
14时41分46秒   997      1825      1.00      0.00  zabbix_agentd
14时41分46秒  1005      1845      4.00      1.00  nagios
14时41分46秒  1005      1855      4.00      0.00  nagios
14时41分46秒  1005      1858      2.00      0.00  nagios
14时41分46秒  1005      1865      2.00      0.00  nagios
14时41分46秒     0     10000      1.00      0.00  supervisord
14时41分46秒     0     10002      1.00      0.00  python
14时41分46秒     0     10003      1.00      0.00  python
14时41分46秒     0     16641      2.00      0.00  kworker/5:0
14时41分46秒     0     21829      1.00      0.00  kworker/2:2
14时41分46秒     0     23448      1.00      0.00  kworker/0:2
14时41分46秒  1004     29890      1.00      0.00  sshd
14时41分46秒  1004     29937      1.00      1.00  htop
14时41分46秒     0     31618      2.00      0.00  kworker/1:0
14时41分46秒     0     31720      1.00      0.00  kworker/1:1
14时41分46秒     0     32456      1.00      0.00  kworker/7:2
14时41分46秒  1005     32533      1.00      0.00  ping
14时41分46秒  1004     32556      1.00      5.00  pidstat
```

```$xslt
[hadoop@mj-9-85 ~]$ pidstat -p 365 -u 1
Linux 3.10.0-229.el7.x86_64 (mj-9-85) 	2020年01月22日 	_x86_64_	(8 CPU)

14时46分12秒   UID       PID    %usr %system  %guest    %CPU   CPU  Command
14时46分13秒  1004       365   47.52  100.00    0.00  100.00     1  sysbench
14时46分14秒  1004       365   62.00  100.00    0.00  100.00     1  sysbench
14时46分15秒  1004       365   50.00  100.00    0.00  100.00     1  sysbench
14时46分16秒  1004       365   59.00  100.00    0.00  100.00     1  sysbench
14时46分17秒  1004       365   51.00  100.00    0.00  100.00     1  sysbench
14时46分18秒  1004       365   54.00  100.00    0.00  100.00     1  sysbench
```
###### 将线程数设置为1000再跑一次
```
[hadoop@mj-9-85 ~]$ sysbench --threads=1000 --max-time=300 threads run
WARNING: --max-time is deprecated, use --time instead
sysbench 1.0.17 (using system LuaJIT 2.0.4)

Running the test with following options:
Number of threads: 1000
Initializing random number generator from current time


Initializing worker threads...

Threads started!


General statistics:
    total time:                          300.2462s
    total number of events:              1531514

Latency (ms):
         min:                                    0.30
         avg:                                  195.94
         max:                                 2818.69
         95th percentile:                      646.19
         sum:                            300085094.06

Threads fairness:
    events (avg/stddev):           1531.5140/74.48
    execution time (avg/stddev):   300.0851/0.07
```
通过设定pid为sysbench的pid后查看线程级的上下文切换情况发现，有很多线程上下文切换
```
pidstat -p 365 -wt 2
平均时间:   UID      TGID       TID   cswch/s nvcswch/s  Command
平均时间:  1004       365         -      0.00      0.00  sysbench
平均时间:  1004         -       365      0.00      0.00  |__sysbench
平均时间:  1004         -       366    333.07   2156.04  |__sysbench
平均时间:  1004         -       367    318.42   1561.39  |__sysbench
平均时间:  1004         -       368    283.76   1998.61  |__sysbench
平均时间:  1004         -       369    328.32   1361.39  |__sysbench
平均时间:  1004         -       370    347.92   2092.28  |__sysbench
平均时间:  1004         -       371    262.77   2003.76  |__sysbench
平均时间:  1004         -       372    308.32   2569.31  |__sysbench
平均时间:  1004         -       373    323.56   1722.18  |__sysbench
平均时间:  1004         -       374    344.55   2095.05  |__sysbench
平均时间:  1004         -       375    298.02   1730.50  |__sysbench
```

```
vmstat 1 
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 663524 142448 2969064    0    0     0     0 1755 2532  1  2 97  0  0
 0  0      0 663084 142448 2969064    0    0     0     0 1796 2907  1  2 97  0  0
 0  0      0 663044 142448 2969104    0    0     0     0 2491 4142  2  3 95  0  0
 0  0      0 663044 142448 2969104    0    0     0     0   21   24  0  0 100  0  0
 0  0      0 663044 142448 2969104    0    0     0     0   20   32  0  0 100  0  0
 0  0      0 663044 142448 2969104    0    0     0     0   52   74  0  0 100  0  0
 0  0      0 663044 142448 2969104    0    0     0     0   27   41  0  0 100  0  0
 0  0      0 663044 142448 2969104    0    0     0     0   23   28  0  0 100  0  0
 0  0      0 663044 142448 2969104    0    0     0     0 1041 1056  1  2 98  0  0
 0  0      0 663040 142448 2969104    0    0     0     0  232  254  1  0 99  0  0
 0  0      0 663020 142448 2969104    0    0     0     0  267  331  1  1 99  0  0
 0  0      0 663044 142448 2969104    0    0     0     0  386  395  0  1 99  0  0
 0  0      0 663184 142448 2969104    0    0     0     0  351  365  0  1 99  0  0
 0  0      0 663292 142448 2969104    0    0     0     0  287  273  1  0 100  0  0
 0  0      0 663112 142448 2969104    0    0     0     0  164  201  1  1 99  0  0
 0  0      0 662988 142448 2969104    0    0     0     0  299  304  1  0 100  0  0
 0  0      0 663044 142448 2969104    0    0     0     0  650  883  1  1 98  0  0
 0  0      0 663436 142448 2969104    0    0     0     0  472  543  1  1 99  0  0
```
通过vmstat命令可以发现，cs和in就已经比较高了，说明上下文切换比较多，通过pidstat -wt发现主要是sysbench的子线程导致的上下文切换很多，in比较多说明终中断的次数也变多了；   

##### 通过观察/proc/interrupts文件变化观察中断的变化情况

```$xslt
watch -d cat /proc/interrupts 
Every 2.0s: cat /proc/interrupts                                                                                                                                                    Wed Jan 22 15:00:40 2020

           CPU0       CPU1	 CPU2       CPU3       CPU4	  CPU5       CPU6	CPU7
  0:        127          0          0          0          0          0          0          0   IO-APIC-edge	 timer
  1:          1          1          1          1          2          2          1          1   IO-APIC-edge	 i8042
  6:          0          0          0          1          1          1          0          0   IO-APIC-edge	 floppy
  8:          0          0          0          0          0          0          0          0   IO-APIC-edge	 rtc0
  9:          0          0          0          0          0          0          0          0   IO-APIC-fasteoi   acpi
 10:          0          0          0          0          0          0          0          0   IO-APIC-fasteoi   virtio2
 11:          0          3          5          3          3          3          2          4   IO-APIC-fasteoi   uhci_hcd:usb1
 12:          0         22         20         20         19         19         20         19   IO-APIC-edge	 i8042
 14:          0          0          0          0          0          0          0          0   IO-APIC-edge	 ata_piix
 15:    2135778         24         22         18         28         34         35         31   IO-APIC-edge	 ata_piix
 40:          0          0          0          0          0          0          0          0   PCI-MSI-edge	 virtio1-config
 41:          0          0          0          0          0          0          0          0   PCI-MSI-edge	 virtio0-config
 42:    1385519        330        332        337        330        324        324        324   PCI-MSI-edge	 virtio1-req.0
 43:          0          0          0          2          0   14514303          0          0   PCI-MSI-edge	 virtio0-input.0
 44:          0          0          0          0          1          0        231          0   PCI-MSI-edge	 virtio0-output.0
NMI:          0          0          0          0          0          0          0          0   Non-maskable interrupts
LOC:   24275281   18515018   10105588    8751800    8554678   27738099    7681466    8382627   Local timer interrupts
SPU:          0          0          0          0          0          0          0          0   Spurious interrupts
PMI:          0          0          0          0          0          0          0          0   Performance monitoring interrupts
IWI:    2787541    2228759     785650     707055     543127    7082944     533384     617596   IRQ work interrupts
RTR:          0          0          0          0          0          0          0          0   APIC ICR read retries
RES:   33065619   30636004   26152455   25464964   24825903   30579875   24516023   24480153   Rescheduling interrupts
CAL:        731     381535	78795     135137      68441     262943      53592     149453   Function call interrupts
TLB:     194732     138848     128454     117164     119203	 89036     353992     108430   TLB shootdowns
TRM:          0          0          0          0          0          0          0          0   Thermal event interrupts
THR:          0          0          0          0          0          0          0          0   Threshold APIC interrupts
MCE:          0          0          0          0          0          0          0          0   Machine check exceptions
MCP:	   7291       7291	 7291       7291       7291	  7291       7291	7291   Machine check polls
ERR:          0
MIS:          0
```
RES(Rescheduling interrupts):重调度中断，表示唤醒空闲状态的cpu来调度新的任务运行，这是多处理器系统(SMP) 中，调度器用来分散任务到不同的cpu的机制，通常也被称为处理器间中断(inter-Processor Interrupts,IPI)   
LOC(Local timer interrupts):本地时钟中断，
IWI(IRQ work interrupts):中断请求工作中断
TLB(TLB shootdowns):
interrupts request：中断请求
MCP(Machine check polls):

### 查看当前系统page大小
```$xslt
getconf PAGESIZE
```

 